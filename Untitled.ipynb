{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b868d37c-907e-461d-816b-355f0053ec69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading required NLTK data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/janelu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/janelu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/janelu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing Car Assistant...\n",
      "Initializing NLP tools...\n",
      "Initializing SQL processor...\n",
      "Loaded 17048 records into SQLite database\n",
      "Successfully initialized SQL database\n",
      "Processing data using SQL...\n",
      "SQL processing completed in 0.73 seconds\n",
      "\n",
      "Training price prediction model...\n",
      "Preprocessing data...\n",
      "Training model (this may take a few minutes)...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Download required NLTK data\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "except LookupError:\n",
    "    print(\"Downloading required NLTK data...\")\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('wordnet')\n",
    "\n",
    "class SQLDataProcessor:\n",
    "    def __init__(self):\n",
    "        self.db_path = 'cars_database.db'\n",
    "        self.create_database()\n",
    "        print(\"Successfully initialized SQL database\")\n",
    "\n",
    "    def create_database(self):\n",
    "        \"\"\"Create SQLite database and import CSV data\"\"\"\n",
    "        try:\n",
    "            desktop = os.path.expanduser(\"~/Desktop\")\n",
    "            csv_path = os.path.join(desktop, \"final project\", \"cars_info.csv\")\n",
    "            \n",
    "            if not os.path.exists(csv_path):\n",
    "                raise FileNotFoundError(f\"CSV file not found at: {csv_path}\")\n",
    "            \n",
    "            # Read CSV\n",
    "            df = pd.read_csv(csv_path)\n",
    "            \n",
    "            # Create SQLite connection\n",
    "            conn = sqlite3.connect(self.db_path)\n",
    "            \n",
    "            # Save to database\n",
    "            df.to_sql('cars', conn, if_exists='replace', index=False)\n",
    "            print(f\"Loaded {len(df)} records into SQLite database\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating database: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def process_data(self):\n",
    "        \"\"\"Process data using SQL queries\"\"\"\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            conn = sqlite3.connect(self.db_path)\n",
    "            \n",
    "            # Complex SQL query with feature engineering\n",
    "            query = \"\"\"\n",
    "            WITH AvgPrices AS (\n",
    "                SELECT \n",
    "                    Brand,\n",
    "                    AVG(Price) as avg_brand_price\n",
    "                FROM cars\n",
    "                GROUP BY Brand\n",
    "            ),\n",
    "            TypeStats AS (\n",
    "                SELECT \n",
    "                    Type,\n",
    "                    AVG(Price) as avg_type_price\n",
    "                FROM cars\n",
    "                GROUP BY Type\n",
    "            )\n",
    "            SELECT \n",
    "                c.*,\n",
    "                2024 - c.Year as Age,\n",
    "                CAST(c.Price AS FLOAT) / (c.Kilometers + 1) as Price_per_km,\n",
    "                ap.avg_brand_price,\n",
    "                ts.avg_type_price,\n",
    "                COUNT(*) OVER (PARTITION BY c.Brand) as brand_count\n",
    "            FROM cars c\n",
    "            JOIN AvgPrices ap ON c.Brand = ap.Brand\n",
    "            JOIN TypeStats ts ON c.Type = ts.Type\n",
    "            \"\"\"\n",
    "            \n",
    "            df = pd.read_sql_query(query, conn)\n",
    "            \n",
    "            processing_time = time.time() - start_time\n",
    "            print(f\"SQL processing completed in {processing_time:.2f} seconds\")\n",
    "            \n",
    "            metrics = {\n",
    "                'records_processed': len(df),\n",
    "                'processing_time': processing_time,\n",
    "                'features_created': ['Age', 'Price_per_km', 'avg_brand_price', \n",
    "                                   'avg_type_price', 'brand_count']\n",
    "            }\n",
    "            \n",
    "            with open('sql_processing_metrics.json', 'w') as f:\n",
    "                json.dump(metrics, f, indent=4)\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in SQL processing: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "class CarChatbot:\n",
    "    def __init__(self):\n",
    "        # Initialize NLP tools\n",
    "        print(\"Initializing NLP tools...\")\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "\n",
    "        try:\n",
    "            # Initialize SQL processor\n",
    "            print(\"Initializing SQL processor...\")\n",
    "            self.sql_processor = SQLDataProcessor()\n",
    "            \n",
    "            # Load and process data\n",
    "            print(\"Processing data using SQL...\")\n",
    "            self.df = self.sql_processor.process_data()\n",
    "            \n",
    "            if len(self.df) == 0:\n",
    "                raise ValueError(\"No data loaded from database\")\n",
    "            \n",
    "            # Initialize and train model\n",
    "            print(\"\\nTraining price prediction model...\")\n",
    "            self.initialize_price_model()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during initialization: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def initialize_price_model(self):\n",
    "        \"\"\"Initialize and train the price prediction model\"\"\"\n",
    "        try:\n",
    "            print(\"Preprocessing data...\")\n",
    "            df_clean = self.df.dropna()\n",
    "            \n",
    "            if len(df_clean) == 0:\n",
    "                raise ValueError(\"No valid data after cleaning\")\n",
    "            \n",
    "            # Encode categorical variables\n",
    "            self.label_encoders = {}\n",
    "            for col in ['Brand', 'Model', 'Type', 'Fuel']:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                df_clean[f'{col}_encoded'] = self.label_encoders[col].fit_transform(df_clean[col])\n",
    "            \n",
    "            features = [\n",
    "                'Age', 'Kilometers', 'Price_per_km', \n",
    "                'Brand_encoded', 'Model_encoded', 'Type_encoded',\n",
    "                'avg_brand_price', 'avg_type_price', 'brand_count'\n",
    "            ]\n",
    "            \n",
    "            X = df_clean[features]\n",
    "            y = df_clean['Price']\n",
    "            \n",
    "            # Scale features\n",
    "            self.scaler = StandardScaler()\n",
    "            X_scaled = self.scaler.fit_transform(X)\n",
    "            \n",
    "            # Split data\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_scaled, y, test_size=0.2, random_state=42\n",
    "            )\n",
    "            \n",
    "            # Train model with optimization\n",
    "            param_grid = {\n",
    "                'n_estimators': [100, 200, 300],\n",
    "                'max_depth': [10, 20, 30],\n",
    "                'min_samples_split': [2, 5, 10]\n",
    "            }\n",
    "            \n",
    "            print(\"Training model (this may take a few minutes)...\")\n",
    "            grid_search = GridSearchCV(\n",
    "                RandomForestRegressor(random_state=42),\n",
    "                param_grid,\n",
    "                cv=5,\n",
    "                scoring='r2',\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X_train, y_train)\n",
    "            self.price_model = grid_search.best_estimator_\n",
    "            \n",
    "            # Evaluate performance\n",
    "            train_pred = self.price_model.predict(X_train)\n",
    "            test_pred = self.price_model.predict(X_test)\n",
    "            \n",
    "            self.train_r2 = r2_score(y_train, train_pred)\n",
    "            self.test_r2 = r2_score(y_test, test_pred)\n",
    "            self.train_mse = mean_squared_error(y_train, train_pred)\n",
    "            self.test_mse = mean_squared_error(y_test, test_pred)\n",
    "            \n",
    "            performance_metrics = {\n",
    "                'train_r2': self.train_r2,\n",
    "                'test_r2': self.test_r2,\n",
    "                'train_mse': self.train_mse,\n",
    "                'test_mse': self.test_mse,\n",
    "                'best_parameters': grid_search.best_params_,\n",
    "                'feature_importance': dict(zip(features, \n",
    "                    self.price_model.feature_importances_))\n",
    "            }\n",
    "            \n",
    "            with open('model_performance.json', 'w') as f:\n",
    "                json.dump(performance_metrics, f, indent=4)\n",
    "            \n",
    "            print(\"\\nModel Performance Summary:\")\n",
    "            print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "            print(f\"Training R² Score: {self.train_r2:.3f}\")\n",
    "            print(f\"Testing R² Score: {self.test_r2:.3f}\")\n",
    "            \n",
    "            if self.test_r2 >= 0.80:\n",
    "                print(\"\\nModel meets performance requirement (R² ≥ 0.80) ✓\")\n",
    "            else:\n",
    "                print(\"\\nModel needs improvement to meet R² ≥ 0.80 requirement ✗\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error in model initialization: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def process_text(self, text):\n",
    "        try:\n",
    "            tokens = word_tokenize(text.lower())\n",
    "            tokens = [self.lemmatizer.lemmatize(t) for t in tokens if t not in self.stop_words]\n",
    "            return tokens\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing text: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    def handle_query(self, query):\n",
    "        try:\n",
    "            tokens = self.process_text(query)\n",
    "            \n",
    "            if 'performance' in tokens:\n",
    "                return self.get_performance_summary()\n",
    "            \n",
    "            if 'find' in tokens or 'search' in tokens or 'show' in tokens:\n",
    "                return self.search_cars(tokens)\n",
    "            \n",
    "            if 'price' in tokens:\n",
    "                return self.handle_price_query(query)\n",
    "            \n",
    "            if 'brand' in tokens or 'brands' in tokens:\n",
    "                return self.list_brands()\n",
    "            \n",
    "            return self.get_help_message()\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error processing query: {str(e)}\"\n",
    "\n",
    "    def search_cars(self, tokens):\n",
    "        try:\n",
    "            filtered = self.df.copy()\n",
    "            \n",
    "            # Filter by brand if specified\n",
    "            for brand in self.df['Brand'].unique():\n",
    "                if brand.lower() in ' '.join(tokens).lower():\n",
    "                    filtered = filtered[filtered['Brand'] == brand]\n",
    "                    break\n",
    "            \n",
    "            if 'budget' in tokens or 'cheap' in tokens:\n",
    "                filtered = filtered[filtered['Price'] <= 30000]\n",
    "            elif 'luxury' in tokens or 'expensive' in tokens:\n",
    "                filtered = filtered[filtered['Price'] >= 80000]\n",
    "\n",
    "            if 'hybrid' in tokens or 'electric' in tokens:\n",
    "                filtered = filtered[filtered['Fuel'].str.contains('Electric', na=False)]\n",
    "            elif 'diesel' in tokens:\n",
    "                filtered = filtered[filtered['Fuel'].str.contains('Diesel', na=False)]\n",
    "\n",
    "            if len(filtered) == 0:\n",
    "                return \"No matches found for your criteria.\"\n",
    "\n",
    "            results = \"Recommendations:\\n\"\n",
    "            for _, car in filtered.head(3).iterrows():\n",
    "                results += f\"\\n{car['Brand']} {car['Model']} {car['Year']}\"\n",
    "                results += f\"\\nPrice: ${car['Price']:,}\"\n",
    "                results += f\"\\nFuel: {car['Fuel']}\"\n",
    "                results += f\"\\nKilometers: {car['Kilometers']:,}\\n\"\n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error searching cars: {str(e)}\"\n",
    "\n",
    "    def handle_price_query(self, query):\n",
    "        try:\n",
    "            for brand in self.df['Brand'].unique():\n",
    "                if brand.lower() in query.lower():\n",
    "                    cars = self.df[self.df['Brand'] == brand]\n",
    "                    return (f\"{brand} price range:\\n\"\n",
    "                           f\"Minimum: ${cars['Price'].min():,}\\n\"\n",
    "                           f\"Maximum: ${cars['Price'].max():,}\\n\"\n",
    "                           f\"Average: ${cars['Price'].mean():,.0f}\")\n",
    "            return \"Please specify a car brand to check prices.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error handling price query: {str(e)}\"\n",
    "\n",
    "    def list_brands(self):\n",
    "        try:\n",
    "            brands = sorted(self.df['Brand'].unique())\n",
    "            return \"Available brands:\\n\" + \"\\n\".join(brands)\n",
    "        except Exception as e:\n",
    "            return f\"Error listing brands: {str(e)}\"\n",
    "\n",
    "    def get_performance_summary(self):\n",
    "        try:\n",
    "            return f\"\"\"\n",
    "Model Performance Details:\n",
    "------------------------\n",
    "Training R² Score: {self.train_r2:.3f}\n",
    "Testing R² Score: {self.test_r2:.3f}\n",
    "Training MSE: {self.train_mse:.2f}\n",
    "Testing MSE: {self.test_mse:.2f}\n",
    "\n",
    "Performance Requirement (R² ≥ 0.80): {'Met ✓' if self.test_r2 >= 0.80 else 'Not Met ✗'}\n",
    "\"\"\"\n",
    "        except Exception as e:\n",
    "            return f\"Error getting performance summary: {str(e)}\"\n",
    "\n",
    "    def get_help_message(self):\n",
    "        return \"\"\"\n",
    "Available commands:\n",
    "- Find cars (e.g., 'find Toyota', 'find electric cars')\n",
    "- Check prices (e.g., 'price of BMW')\n",
    "- Show model performance\n",
    "- List available brands\n",
    "\n",
    "You can also specify:\n",
    "- Price range: 'budget' or 'luxury'\n",
    "- Fuel type: 'electric', 'hybrid', 'diesel'\n",
    "\"\"\"\n",
    "\n",
    "def main():\n",
    "    while True:  # Main program loop\n",
    "        try:\n",
    "            print(\"\\nInitializing Car Assistant...\")\n",
    "            bot = CarChatbot()\n",
    "            print(\"\\nEnhanced Car Assistant: Ready (type 'quit' to exit)\")\n",
    "            print(bot.get_help_message())\n",
    "            \n",
    "            while True:  # Command loop\n",
    "                try:\n",
    "                    query = input(\"\\nYou: \").strip()\n",
    "                    if query.lower() == 'quit':\n",
    "                        print(\"Goodbye!\")\n",
    "                        return\n",
    "                    \n",
    "                    if not query:\n",
    "                        print(\"Please enter a command or type 'quit' to exit.\")\n",
    "                        continue\n",
    "                        \n",
    "                    response = bot.handle_query(query)\n",
    "                    print(\"\\nAssistant:\", response)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"\\nError processing command: {str(e)}\")\n",
    "                    retry = input(\"Would you like to try another command? (yes/no): \").lower()\n",
    "                    if retry != 'yes':\n",
    "                        break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError initializing system: {str(e)}\")\n",
    "            retry = input(\"\\nWould you like to restart the program? (yes/no): \").lower()\n",
    "            if retry != 'yes':\n",
    "                print(\"Exiting program...\")\n",
    "                break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df740f2-73a5-432b-9f03-e5b95aef3c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
